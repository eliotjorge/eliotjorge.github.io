---
title: "¬øQu√© es OLS (M√≠nimos Cuadrados Ordinarios)?"
date: 2025-04-13
description: "Descubre qu√© es OLS (M√≠nimos Cuadrados Ordinarios) y c√≥mo se utiliza en an√°lisis estad√≠stico para estimar relaciones entre variables de forma precisa y eficiente."
categories: [data science, ols, estad√≠stica]
tags: [data science, ols, estad√≠stica]
render_with_liquid: false
---

OLS significa **Ordinary Least Squares** en ingl√©s, o **M√≠nimos Cuadrados Ordinarios** en espa√±ol.

Imagina que tienes muchos puntos dibujados en un gr√°fico. Cada punto representa una persona y muestra:

- Cu√°nto fue su **pulso promedio** (`Average_Pulse`)
- Cu√°ntas **calor√≠as quem√≥** (`Calorie_Burnage`)

üìà Lo que queremos es **dibujar una l√≠nea recta** que pase lo m√°s cerca posible de todos los puntos.  
Esa l√≠nea sirve para hacer predicciones. Por ejemplo:

> ‚ÄúSi alguien tiene un pulso promedio de 140, quemar√° m√°s o menos X calor√≠as.‚Äù

OLS es una t√©cnica matem√°tica que **busca la mejor l√≠nea recta posible**.  
Para hacerlo, **mide qu√© tan lejos est√°n los puntos de la l√≠nea**, y encuentra la l√≠nea que **minimiza el error total** (los errores se elevan al cuadrado para evitar negativos y dar m√°s peso a los errores grandes).

---

## üêç Ejemplo en Python paso a paso

```python
import pandas as pd
import statsmodels.formula.api as smf

# Cargar los datos desde un archivo CSV
full_health_data = pd.read_csv("data.csv", header=0, sep=",")

# Crear el modelo de regresi√≥n lineal con OLS
model = smf.ols('Calorie_Burnage ~ Average_Pulse', data = full_health_data)

# Ajustar (entrenar) el modelo con los datos
results = model.fit()

# Mostrar un resumen con los resultados
print(results.summary())
```

---

## üß† Explicaci√≥n del c√≥digo

### `import pandas as pd`
Importa la librer√≠a **pandas**, que se usa para leer y trabajar con datos en forma de tabla (como Excel).

### `import statsmodels.formula.api as smf`
Importa la librer√≠a `statsmodels`, que permite hacer modelos estad√≠sticos como la **regresi√≥n lineal OLS**.

### `full_health_data = pd.read_csv("data.csv")`
Lee un archivo CSV llamado `data.csv`, que contiene los datos de personas: pulso promedio y calor√≠as quemadas.

### `model = smf.ols('Calorie_Burnage ~ Average_Pulse', data=...)`
Crea un modelo OLS que quiere predecir `Calorie_Burnage` a partir de `Average_Pulse`.

üó£ Traducci√≥n:  
> "Intenta dibujar una l√≠nea que relacione el pulso promedio con las calor√≠as quemadas."

### `results = model.fit()`
Ajusta (entrena) el modelo. Calcula cu√°l es la **mejor l√≠nea posible** usando los datos.

### `print(results.summary())`
Muestra el **resumen del modelo** con todos los detalles y estad√≠sticas.

---

## üßæ ¬øQu√© dice el resumen?

Aqu√≠ est√° lo que ver√°s al imprimir `results.summary()`:

```
                            OLS Regression Results
==============================================================================
Dep. Variable:        Calorie_Burnage   R-squared:                       0.000
Model:                            OLS   Adj. R-squared:                 -0.006
Method:                 Least Squares   F-statistic:                   0.04975
Date:                Tue, 24 Nov 2020   Prob (F-statistic):              0.824
Time:                        12:26:11   Log-Likelihood:                -1145.8
No. Observations:                 163   AIC:                             2296.
Df Residuals:                     161   BIC:                             2302.
Df Model:                           1
Covariance Type:            nonrobust
=================================================================================
                    coef    std err          t      P>|t|      [0.025      0.975]
---------------------------------------------------------------------------------
Intercept       346.8662    160.615      2.160      0.032      29.682     664.050
Average_Pulse     0.3296      1.478      0.223      0.824      -2.588       3.247
==============================================================================
Omnibus:                      124.542   Durbin-Watson:                   1.620
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              938.541
Skew:                           2.927   Prob(JB):                    1.58e-204
Kurtosis:                      13.195   Cond. No.                         811.
==============================================================================
```


---

### üßæ Salida completa de `results.summary()` (Explicaci√≥n en 3 bloques)

####üîπ **Bloque 1: Informaci√≥n general del modelo**
```text
                            OLS Regression Results
==============================================================================
Dep. Variable:        Calorie_Burnage   R-squared:                       0.000
Model:                            OLS   Adj. R-squared:                 -0.006
Method:                 Least Squares   F-statistic:                   0.04975
Date:                Tue, 24 Nov 2020   Prob (F-statistic):              0.824
Time:                        12:26:11   Log-Likelihood:                -1145.8
No. Observations:                 163   AIC:                             2296.
Df Residuals:                     161   BIC:                             2302.
Df Model:                           1
Covariance Type:            nonrobust
```

üß† ¬øQu√© significa cada cosa?

- **Dep. Variable:** la variable que queremos predecir (en este caso, `Calorie_Burnage`)
- **R-squared (R¬≤):** 0.000 ‚Üí el modelo no explica casi nada de la variaci√≥n.
- **Adj. R-squared:** como R¬≤ pero ajustado por el n√∫mero de variables. Aqu√≠ tambi√©n es malo.
- **F-statistic y Prob (F-statistic):** indican si el modelo completo tiene sentido. Aqu√≠ no: `p = 0.824` (mayor que 0.05).
- **Log-Likelihood, AIC, BIC:** son medidas t√©cnicas de calidad del modelo (valores m√°s bajos = mejor). Son √∫tiles para comparar varios modelos.
- **No. Observations:** n√∫mero de datos que se usaron (163).
- **Df Model y Df Residuals:** grados de libertad. Aqu√≠ hay 1 predictor (`Average_Pulse`), y 161 residuos.

---

#### üîπ **Bloque 2: Tabla de coeficientes (la ecuaci√≥n del modelo)**
```text
=================================================================================
                    coef    std err          t      P>|t|      [0.025      0.975]
---------------------------------------------------------------------------------
Intercept       346.8662    160.615      2.160      0.032      29.682     664.050
Average_Pulse     0.3296      1.478      0.223      0.824      -2.588       3.247
=================================================================================
```

Esto representa la ecuaci√≥n de la recta:

üìè **Calorie_Burnage = 346.87 + 0.33 √ó Average_Pulse**

Pero:

- `P>|t|` para `Average_Pulse` es **0.824**, muy alto ‚Üí **no es un predictor v√°lido**.
-  Si es menor de **0.05**, es importante.
- El intervalo de confianza `[0.025, 0.975]` para `Average_Pulse` incluye el 0 ‚Üí tampoco hay efecto claro.
- En este caso, `Average_Pulse` tiene un **p = 0.824**, lo cual significa que **es casi seguro que NO hay relaci√≥n** entre pulso y calor√≠as.

‚úÖ El intercepto **s√≠ es significativo** (`p = 0.032`), pero no sirve de mucho si el predictor no explica nada.


---

#### üîπ **Bloque 3: Diagn√≥stico del modelo (calidad de los residuos)**
```text
Omnibus:                      124.542   Durbin-Watson:                   1.620
Prob(Omnibus):                  0.000   Jarque-Bera (JB):              938.541
Skew:                           2.927   Prob(JB):                    1.58e-204
Kurtosis:                      13.195   Cond. No.                         811.
```

üß™ Este bloque analiza si **los errores del modelo (residuos)** se comportan como deber√≠an.

- **Omnibus, JB, Prob(JB):** pruebas de normalidad. Aqu√≠ el p-valor es muy bajo ‚Üí los errores **no son normales**.
- **Skew (asimetr√≠a):** 2.927 ‚Üí mucha asimetr√≠a. Idealmente deber√≠a ser 0.
- **Kurtosis:** 13.195 ‚Üí muy alto. Deber√≠a estar cerca de 3.
- **Durbin-Watson:** 1.620 ‚Üí mide autocorrelaci√≥n. Valores cerca de 2 son aceptables.
- **Cond. No. (n√∫mero de condici√≥n):** 811 ‚Üí indica posible multicolinealidad. Menor de 30 = bien; m√°s de 1000 = problema.

---

## üñºÔ∏è Representaci√≥n gr√°fica

![regresion_lineal_ols](https://github.com/user-attachments/assets/376a6c9e-82b7-4ad2-8752-f0c206dd3aeb)


**Cruces amarillas:** son los datos reales de personas: su pulso promedio y calor√≠as quemadas.

**L√≠nea roja:** es la l√≠nea que OLS ha intentado ajustar. Como puedes ver, est√° casi horizontal porque no hay relaci√≥n clara entre los datos.

Es como si el modelo dijera:

> "Da igual el pulso, la cantidad de calor√≠as quemadas no cambia mucho."

Por eso el R-squared era cercano a 0.

---

## üßÉ ¬øEn resumen sencillo?

- **OLS** es una t√©cnica que dibuja la **mejor l√≠nea recta** entre dos cosas (por ejemplo, pulso y calor√≠as).
- En tu c√≥digo, OLS intent√≥ encontrar esa l√≠nea.
- Pero el resultado dice que **no hay relaci√≥n**: el pulso **no ayuda a predecir** cu√°ntas calor√≠as quema una persona, al menos con estos datos.
